# -*- coding: utf-8 -*-
"""roberta_64.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hzst28NLHxFb1d8yKSph9T4SWkRaxgOI

## Setup
"""

!pip install tokenizers
!pip install transformers

#importing libraries
import os
import re
import json
import string
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tokenizers import BertWordPieceTokenizer
from transformers import BertTokenizer, TFBertModel, BertConfig

max_len = 384
#configuration = BertConfig()  # default parameters and configuration for BERT

from transformers import RobertaTokenizer, TFRobertaForQuestionAnswering, RobertaTokenizerFast, TFRobertaModel
import tensorflow as tf

"""## Set-up BERT tokenizer

"""

# Save the slow pretrained tokenizer
slow_tokenizer =RobertaTokenizer.from_pretrained('roberta-base')
save_path = "roberta_base_uncased/"
if not os.path.exists(save_path):
    os.makedirs(save_path)
slow_tokenizer.save_pretrained(save_path)
import tokenizers
# Load the fast tokenizer from saved file

#tokenizer = ByteLevelBPETokenizer(vocab="roberta_base_uncased/vocab.json", lowercase= True)
tokenizer = tokenizers.ByteLevelBPETokenizer(
    vocab='/content/vocab-roberta-base.json', 
    merges='/content/merges-roberta-base.txt', 
    lowercase=True,
    add_prefix_space=True
)
#tokenizer = BertWordPieceTokenizer("roberta_base_uncased/vocab.json", lowercase=True)

"""## Load the data

"""

train_data_url = "https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json"
train_path = keras.utils.get_file("train.json", train_data_url)
eval_data_url = "https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"
eval_path = keras.utils.get_file("eval.json", eval_data_url)

"""## Preprocess the data

1. Go through the JSON file and store every record as a `SquadExample` object.
2. Go through each `SquadExample` and create `x_train, y_train, x_eval, y_eval`.

"""

class SquadExample:
    def __init__(self, question, context, start_char_idx, answer_text, all_answers):
        self.question = question
        self.context = context
        self.start_char_idx = start_char_idx
        self.answer_text = answer_text
        self.all_answers = all_answers
        self.skip = False

    def preprocess(self):
        context = self.context
        question = self.question
        answer_text = self.answer_text
        start_char_idx = self.start_char_idx

        # Clean context, answer and question
        context = " ".join(str(context).split())
        question = " ".join(str(question).split())
        answer = " ".join(str(answer_text).split())
        #print(answer)
        # Find end character index of answer in context
        end_char_idx = start_char_idx + len(answer)
        if end_char_idx >= len(context):
            self.skip = True
            return

        # Mark the character indexes in context that are in answer
        is_char_in_ans = [0] * len(context)
        for idx in range(start_char_idx, end_char_idx):
            is_char_in_ans[idx] = 1
        '''
        if(True):
          print(context)
          print(answer)
          print(question)
          print(start_char_idx)
          print(end_char_idx)
          print(is_char_in_ans)
          print(sum(is_char_in_ans))
        '''
        # Tokenize context
        tokenized_context = tokenizer.encode(context)
        
        # Find tokens that were created from answer characters
        offsets = []
        idx = 0
        '''
        for t in enumerate(tokenized_context.ids):
            w = tokenizer.decode([t])
            offsets.append((idx, idx+len(w)))
            idx+=len(w)
        print(idx)
        ans_token_idx = []
        for i, (a,b) in enumerate(offsets):
          sm=np.sum(is_char_in_ans[a:b])
          if(sm>0):
            ans_token_idx.append(i)
        '''
        ans_token_idx = []
        for idx, (start, end) in enumerate(tokenized_context.offsets):
            if sum(is_char_in_ans[start:end]) > 0:
                ans_token_idx.append(idx)
        
        if len(ans_token_idx) == 0:
            self.skip = True
            return
        
        # Find start and end token index for tokens from answer
        start_token_idx = ans_token_idx[0]
        end_token_idx = ans_token_idx[-1]

        # Tokenize question
        tokenized_question = tokenizer.encode(question)

        # Create inputs
        input_ids = tokenized_context.ids + tokenized_question.ids[1:]
        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(
            tokenized_question.ids[1:]
        )
        attention_mask = [1] * len(input_ids)

        # Pad and create attention masks.
        # Skip if truncation is needed
        padding_length = max_len - len(input_ids)
        if padding_length > 0:  # pad
            input_ids = input_ids + ([0] * padding_length)
            attention_mask = attention_mask + ([0] * padding_length)
            token_type_ids = token_type_ids + ([0] * padding_length)
        elif padding_length < 0:  # skip
            self.skip = True
            return

        self.input_ids = input_ids
        self.token_type_ids = token_type_ids
        self.attention_mask = attention_mask
        self.start_token_idx = start_token_idx
        self.end_token_idx = end_token_idx
        self.context_token_to_char = tokenized_context.offsets


with open(train_path) as f:
    raw_train_data = json.load(f)

with open(eval_path) as f:
    raw_eval_data = json.load(f)

#Creating Squad example
def create_squad_examples(raw_data):
    squad_examples = []
    for item in raw_data["data"]:
        for para in item["paragraphs"]:
            context = para["context"]
            for qa in para["qas"]:
                question = qa["question"]
                answer_text = qa["answers"][0]["text"]
                all_answers = [_["text"] for _ in qa["answers"]]
                start_char_idx = qa["answers"][0]["answer_start"]
                squad_eg = SquadExample(
                    question, context, start_char_idx, answer_text, all_answers
                )
                squad_eg.preprocess()
                squad_examples.append(squad_eg)
                
    return squad_examples

#Creating tagets
def create_inputs_targets(squad_examples):
    dataset_dict = {
        "input_ids": [],
        "token_type_ids": [],
        "attention_mask": [],
        "start_token_idx": [],
        "end_token_idx": [],
    }
    for item in squad_examples:
        if item.skip == False:
            for key in dataset_dict:
                dataset_dict[key].append(getattr(item, key))
    for key in dataset_dict:
        dataset_dict[key] = np.array(dataset_dict[key])

    x = [
        dataset_dict["input_ids"],
        dataset_dict["token_type_ids"],
        dataset_dict["attention_mask"],
    ]
    y = [dataset_dict["start_token_idx"], dataset_dict["end_token_idx"]]
    return x, y

#training Data
train_squad_examples = create_squad_examples(raw_train_data)
x_train, y_train = create_inputs_targets(train_squad_examples)
print(f"{len(train_squad_examples)} training points created.")

#Evaluation Data
eval_squad_examples = create_squad_examples(raw_eval_data)
x_eval, y_eval = create_inputs_targets(eval_squad_examples)
print(f"{len(eval_squad_examples)} evaluation points created.")

#Decay LR
initial_learning_rate = 5e-5
batchSize = 256
decaySteps=(x_train[0].shape[0])//batchSize
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate, decay_steps=decaySteps, decay_rate=0.1, staircase=True)

"""Create the Question-Answering Model using BERT and Functional API

"""

def create_model():
    ## BERT encoder
    encoder = TFRobertaModel.from_pretrained('roberta-base', output_hidden_states = True)

    ## QA Model -  Stacking 2 NN and a embedding layer to get better result
    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)
    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)
    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)
    embedding = encoder(
    input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, output_hidden_states = True)[0]
    start_logits = layers.Dense(1, name="start_logit", use_bias=False)(embedding)
    start_logits = layers.Flatten()(start_logits)

    end_logits = layers.Dense(1, name="end_logit", use_bias=False)(embedding)
    end_logits = layers.Flatten()(end_logits)
    
    start_probs = layers.Activation(keras.activations.softmax)(start_logits)
    end_probs = layers.Activation(keras.activations.softmax)(end_logits)

    model = keras.Model(
        inputs=[input_ids, token_type_ids, attention_mask],
        outputs=[start_probs, end_probs],
    )
    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)
    optimizer = keras.optimizers.Adam(lr  = 5e-5)
    model.compile(optimizer=optimizer, loss=[loss, loss])
    return model

"""This code should preferably be run on Google Colab TPU runtime.
With Colab TPUs, each epoch will take 5-6 minutes.

"""

use_tpu = True
if use_tpu:
    # Create distribution strategy
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()
    strategy = tf.distribute.TPUStrategy(tpu)

    # Create model
    with strategy.scope():
        model = create_model()
else:
    model = create_model()

model.summary()

"""## Create evaluation Callback

This callback will compute the exact match score using the validation data
after every epoch.

"""

f_score_list = []
exact_match_score_list = []

def normalize_text(text):
    text = text.lower()

    # Remove punctuations
    exclude = set(string.punctuation)
    text = "".join(ch for ch in text if ch not in exclude)

    # Remove articles
    regex = re.compile(r"\b(a|an|the)\b", re.UNICODE)
    text = re.sub(regex, " ", text)

    # Remove extra white space
    text = " ".join(text.split())
    return text


class FScore(keras.callbacks.Callback):
    def __init__(self, x_eval, y_eval):
        self.x_eval = x_eval
        self.y_eval = y_eval

    def on_epoch_end(self, epoch, logs=None):
        pred_start, pred_end = self.model.predict(self.x_eval)
        print("start f score")
        f_score = 0.0
        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]
        count = 0.0
        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):
            squad_eg = eval_examples_no_skip[idx]
            prec = 0.0
            rec = 0.0
            offsets = squad_eg.context_token_to_char
            start = np.argmax(start)
            end = np.argmax(end)
            if start >= len(offsets):
                continue
            pred_char_start = offsets[start][0]
            if end < len(offsets):
                pred_char_end = offsets[end][1]
                pred_ans = squad_eg.context[pred_char_start:pred_char_end]
            else:
                pred_ans = squad_eg.context[pred_char_start:]

            normalized_pred_ans = normalize_text(pred_ans)
            normalized_true_ans_list = [normalize_text(_) for _ in squad_eg.all_answers]
            normalized_pred_ans_tokens = normalized_pred_ans.split()
            count+=1
            temp_f_score = 0
            for normalize_true_ans in normalized_true_ans_list:
              normalize_true_ans_tokens = normalize_true_ans.split()
              if len(normalized_pred_ans_tokens) == 0 or len(normalize_true_ans_tokens) == 0:
                temp_f_score=1
                break
              common_tokens = set(normalized_pred_ans_tokens) & set(normalize_true_ans_tokens)
              # if there are no common tokens then f1 = 0
              if len(common_tokens) == 0:
                continue
              #Precision and Recall calculation
              prec = len(common_tokens) / len(normalized_pred_ans_tokens)
              rec = len(common_tokens) / len(normalize_true_ans_tokens)
              #Picking the max fscore score across the data set
              temp_f_score = max(temp_f_score, 2 * (prec * rec) / (prec + rec))
            f_score+=temp_f_score
        
        #Taking average of max f score over epochs
        f_score = f_score/count
          
        print(f"\nepoch={epoch+1}, f score={f_score:.2f}")
        f_score_list.append(f_score)
        
class ExactMatch(keras.callbacks.Callback):
    """
    Each `SquadExample` object contains the character level offsets for each token
    in its input paragraph. We use them to get back the span of text corresponding
    to the tokens between our predicted start and end tokens.
    All the ground-truth answers are also present in each `SquadExample` object.
    We calculate the percentage of data points where the span of text obtained
    from model predictions matches one of the ground-truth answers.
    """

    def __init__(self, x_eval, y_eval):
        self.x_eval = x_eval
        self.y_eval = y_eval

    def on_epoch_end(self, epoch, logs=None):
        pred_start, pred_end = self.model.predict(self.x_eval)
        count = 0
        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]
        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):
            squad_eg = eval_examples_no_skip[idx]
            offsets = squad_eg.context_token_to_char
            start = np.argmax(start)
            end = np.argmax(end)
            if start >= len(offsets):
                continue
            pred_char_start = offsets[start][0]
            if end < len(offsets):
                pred_char_end = offsets[end][1]
                pred_ans = squad_eg.context[pred_char_start:pred_char_end]
            else:
                pred_ans = squad_eg.context[pred_char_start:]

            normalized_pred_ans = normalize_text(pred_ans)
            normalized_true_ans = [normalize_text(_) for _ in squad_eg.all_answers]
            #For exact match
            if normalized_pred_ans in normalized_true_ans:
                count += 1
        #Calcualting exact match
        acc = count / len(self.y_eval[0])
        print(f"\nepoch={epoch+1}, exact match score={acc:.2f}")
        exact_match_score_list.append(acc)

"""## Train and Evaluate

"""

exact_match_callback = ExactMatch(x_eval, y_eval)
f_score_callback = FScore(x_eval, y_eval)
model.fit(
    x_train,
    y_train,
    epochs=3,  # For demonstration, 3 epochs are recommended
    verbose=1,
    batch_size=64,
    callbacks=[exact_match_callback, f_score_callback]
)
#Saving model
model.save('./content/drive/model_roberta_squad_64.h5')

"""**Saving Fscore and Exact Match**"""

epoch = [1,2,3]

f_score_list

from google.colab import drive
drive.mount('/content/drive')

exact_match_score_list

import pandas as pd
d = {'exact_match': exact_match_score_list, 'f_score': f_score_list, 'epoch':epoch}

df = pd.DataFrame(d)

df

df.to_csv('./content/drive/squad_roberta_64.csv', index=False)



